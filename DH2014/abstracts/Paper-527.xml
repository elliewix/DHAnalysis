<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><title>DHArchive</title><meta http-equiv="content-type" content="text/html; charset=utf-8" /><link rel="stylesheet" type="text/css" href="/s/dharchive.css"></link><link rel="shortcut icon" type="image/x-icon" href="favicon.ico" /></head><body><header><a href="/"><img src="/i/logo.png" id="logo" /><h1><acronym>dharchive</acronym>.org</h1></a></header><section><a href="/?c=DH2014"><img src="/data/figures/DH2014/banner.jpg" class="banner"/></a><div id="read"><aside><a class="btn" href="javascript:window.print();"><img src="/i/print.png"/> Print</a><a class="btn" href="/data/xml/DH2014/Paper-527.xml"><img src="/i/download.png"/> XML</a></aside><?xml version="1.0" encoding="utf-8"?>
<article xmlns="http://www.tei-c.org/ns/1.0" xmlns:xhtml="http://www.w3.org/1999/xhtml" xmlns:tei="http://www.tei-c.org/ns/1.0">
  <header xmlns="">
    <h1>The social pleasure of the text: Applying digital humanities methods to reception studies</h1>
    <ul id="details">
      <li><label>Category:</label>Long Paper</li>
      <li><label>Session:</label>7</li>
      <li><label>Date:</label>2014-07-11<label>Time:</label>11:00:00</li>
      <li><label>Room:</label>413 - Amphimax</li>
    </ul>
    <ul id="authors">
      <li>
        <a href="mailto:anouk.lang@gmail.com"><span class="author-surname">Lang</span>,
									<span class="author-forename">Anouk</span></a>
        <a href="http://www.google.com/#q=Lang, Anouk">
          <img src="/i/search.png"/>
        </a>
        <span class="author-affiliation">University of Strathclyde</span>
      </li>
    </ul>
  </header>
  <p xmlns=""/>
  <p xmlns=""> How do readers use social media to express the value and the pleasure that the experience of reading holds for them? And, given the rapidity with which corpora gathered from social media are growing, what kinds of methods are most useful for analysing this kind of (big) data so as to cast light on the phenomenology of reading experiences? This paper seeks to answer these questions by presenting the findings of a project on developing methods for analysing and evaluating literary engagement in digital contexts, funded by the Arts and Humanities Research Council under the auspices of the Cultural Value Project.<cite href="#n1">1</cite>
It will report on what can be learnt from the large amount of user-generated data available on microblogging services and social network sites about the value that reading brings to the lives of individuals and communities, and will offer an evaluation of the various analytical tools and methods available to scholars working on reading and reception studies who wish to include born-digital data in their research.</p>
  <p xmlns="">Work in reception studies is increasingly focusing on the ways that an understanding of the significance of individual reading experiences can be enriched by attending to occasions when readers join with others to express opinions about a text, and work together to construct its meaning. Scholars have argued that it is in fact in these acts of <em>public </em>negotiation of meaning – for example book group discussions – that readers can be observed doing the <em>private </em>cognitive work of textual engagement, as their interpretations change in the act of articulating their response in a social context.<cite href="#n2">2</cite>
The fact that the rich textual data available on social media is often generated by readers in conversation with friends or acquaintances, in contexts quite different to interviews with researchers or questionnaires which might prompt a higher level of self-editing, makes it even more compelling to work with.<cite href="#n3">3</cite>
The obvious advantage of working with this sort of born-digital material is that it lends itself to analysis using the growing number of tools and methods being developed within digital humanities, which have the power to integrate textual and geospatial information, and to identify lexical trends in time-stamped data. Such computational methods not only offer scholars the opportunity to analyse much larger bodies of text than is ordinarily possible for individual researchers to examine through close reading, but also to draw on, and discover patterns in, temporal and geospatial metadata.</p>
  <p xmlns="">Data for this project was gathered from two different social media platforms, the microblogging platform Twitter and the book collection website LibraryThing.<cite href="#n4">4</cite>
For the Twitter data, searches were performed for literary prizes (for example <em>Man Booker Prize</em> and <em>Nobel</em>), author names (for example [Eleanor] <em>Catton</em> and [Alice] <em>Munro</em>), and hashtags commonly used to signal reading-related tweets (for example <em>#goodreads</em> and <em>#mustread</em>). For the LibraryThing data, the results of the Twitter searches were used to suggest particular books to investigate, so as to enable a comparison of the way readers discussed books on the two platforms. The numerical review scores and the text of user reviews of these books were stored in a database, along with metadata about the user. While some interesting work on literary value has already been done by scraping data from Amazon,<cite href="#n5">5</cite>
LibraryThing was selected for this project as it is a platform where readers gather primarily to share information voluntarily about books in ways not (directly) linked to commercial activity. Moreover, it is also possible to link some of this information to users’ reported geographic location, something which cannot be done with Amazon data.</p>
  <p xmlns="">Various digital methods were then applied to the resulting datasets: thematic analysis using methods from corpus linguistics, analysis of trends in word usage over time using a burst detection algorithm, and geospatial analysis.</p>
  <h2 xmlns="">1) Thematic analysis</h2>
  <p xmlns="">Analytical techniques from corpus linguistics were employed to identify patterns of unusually prominent words, phrases and grammatical constructions. The textual data gathered were tagged with the CLAWS part-of-speech tagger,<cite href="#n6">6</cite>
and the concordance program AntConc<cite href="#n7">7</cite> was then used to identify the most frequent words, determine their statistical significance as compared to a reference corpus, find the terms that most commonly collocated with them, and carry out other analytical procedures. Sub-corpora were separated out by hashtag and geographical location, and analysed individually.</p>
  <h2 xmlns="">2) Temporal analysis</h2>
  <p xmlns="">As all the Twitter data and a significant proportion of the LibraryThing data is time-stamped, it presented an opportunity to analyse trends over time, something that can be done with burst detection analysis in order to gauge how influential particular words or hashtags have been over time.<cite href="#n8">8</cite>
The Sci2 tool<cite href="#n9">9</cite>
was used to perform burst detection, and to visualise the results as temporal bar graphs. Terms that “burst” into prominence were then fed back into the corpus linguistic analysis, for example in order to examine the collocation patterns around them, and to attend to the context in which they initially appeared. </p>
  <h2 xmlns="">3) Geospatial analysis</h2>
  <p xmlns="">The software package ArcGIS was used to create a GIS database including layers derived from the Twitter and LibraryThing data, to see where particular geographical patternings in the search terms and hashtags occurred. (While not all tweets or contributions to LibraryThing have georeferences attached to them, a large enough number do to make this form of analysis worthwhile.) These data were then layered against census data (such as level of educational attainment or socioeconomic status) aggregated at the output area level, in order to enable semantic patterns in the articulation of reading-related tweets and posts to be considered alongside the demographic features of the places where they were articulated. </p>
  <p xmlns="">The paper will set out the advantages offered by thematic, temporal and geospatial analyses, and suggest the components of cultural value which are best addressed by each, while also considering how these different forms of analysis may be productively combined.</p>
  <h2 xmlns="">References</h2>
  <p xmlns="">
1. 							<a href="http://www.ahrc.ac.uk/Funded-Research/Funded-themes-and-programmes/Cultural-Value-Project/">www.ahrc.ac.uk/Funded-Research/Funded-themes-and-programmes/Cultural-Value-Project/</a></p>
  <p xmlns="">2. <strong>Daniel Allington and Bethan Benwell</strong> (2012), <em>Reading the Reading Experience: An Ethnomethodological Approach to ‘Booktalk’</em>, in From Codex to Hypertext: Reading at the Turn of the Twenty-first Century, ed. by Anouk Lang (Amherst, MA: University of Massachusetts Press, 2012), pp. 217–233.
						</p>
  <p xmlns="">3. <strong>Rhiannon Bury, Ruth Deller and Adam Greenwood</strong> (2013), <em>From Usenet to Tumblr: The Changing Role of Social Media,</em> Participations 10, 299–318.
						</p>
  <p xmlns="">
4. 							https://twitter.com/; <a href="http://www.librarything.com/.">www.librarything.com/.</a></p>
  <p xmlns="">
							5. <strong>Ed Finn</strong> (2011), <em>Becoming Yourself: The Afterlife of Reception,</em> Pamphlets of the Stanford Literary Lab 3. 15 Sept 2011. <a href="http://litlab.stanford.edu/?page_id=255.">litlab.stanford.edu/?page_id=255.</a> 1 Nov 2013.
						</p>
  <p xmlns="">
6. 							<a href="http://ucrel.lancs.ac.uk/claws/.">ucrel.lancs.ac.uk/claws/.</a></p>
  <p xmlns="">
7. 							<a href="http://www.antlab.sci.waseda.ac.jp/software.html.">www.antlab.sci.waseda.ac.jp/software.html.</a></p>
  <p xmlns="">
8. 							<strong>Jon Kleinberg</strong> b(2002), <em>Bursty and Hierarchical Structure in Streams,</em> Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD  ’02 (New York: ACM, 2002), pp. 91–101.
						</p>
  <p xmlns="">
9 							<a href="http://sci2.cns.iu.edu.">sci2.cns.iu.edu.</a></p>
</article>
</div></section><footer><hr/></footer></body></html>